{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toche7/AI_ITM/blob/main/Lab16_T5_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T5_Transformer\n"
      ],
      "metadata": {
        "id": "sKZhYHDTavVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Importing Libraries"
      ],
      "metadata": {
        "id": "GUxFBztNa16n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "eORjqd4kSBWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sentencepiece"
      ],
      "metadata": {
        "id": "66DCc_7ZWI0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MgiB2eRRghq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small', return_dict=True)"
      ],
      "metadata": {
        "id": "sF1aEak5Tb8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Text Summarization"
      ],
      "metadata": {
        "id": "D1s9JIW6UXzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_piece_sequence = (\"The series focuses on Monkey D. Luffy, a young man made of rubber, who, inspired by his childhood idol,\"\n",
        "             \"the powerful pirate Red-Haired Shanks, sets off on a journey from the East Blue Sea to find the mythical treasure,\"\n",
        "             \"the One Piece, and proclaim himself the King of the Pirates. In an effort to organize his own crew, the Straw Hat Pirates,\"\n",
        "             \"Luffy rescues and befriends a pirate hunter and swordsman named Roronoa Zoro, and they head off in search of the \"\n",
        "             \"titular treasure. They are joined in their journey by Nami, a money-obsessed thief and navigator; Usopp, a sniper \"\n",
        "             \"and compulsive liar; and Sanji, a perverted but chivalrous cook. They acquire a ship, the Going Merry, and engage in confrontations\"\n",
        "             \"with notorious pirates of the East Blue. As Luffy and his crew set out on their adventures, others join the crew later in the series, \"\n",
        "             \"including Tony Tony Chopper, an anthropomorphized reindeer doctor; Nico Robin, an archaeologist and former Baroque Works assassin; \"\n",
        "             \"Franky, a cyborg shipwright; Brook, a skeleton musician and swordsman; and Jimbei, a fish-man helmsman and former member of the Seven \"\n",
        "             \"Warlords of the Sea. Once the Going Merry is damaged beyond repair, Franky builds the Straw Hat Pirates a new ship, the Thousand Sunny,\"\n",
        "             \"Together, they encounter other pirates, bounty hunters, criminal organizations, revolutionaries, secret agents, and soldiers of the\"\n",
        "             \"corrupt World Government, and various other friends and foes, as they sail the seas in pursuit of their dreams.\")"
      ],
      "metadata": {
        "id": "1HALj_woR5tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer.encode(\"summarize: \" + one_piece_sequence,\n",
        "                          return_tensors='pt',\n",
        "                          max_length=512,\n",
        "                          truncation=True)"
      ],
      "metadata": {
        "id": "EBNDNpBHTkpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarization_ids = model.generate(inputs, max_length=80, min_length=40, length_penalty=5., num_beams=2)"
      ],
      "metadata": {
        "id": "vC64zDLdT4vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarization = tokenizer.decode(summarization_ids[0])"
      ],
      "metadata": {
        "id": "p6NnkC8pUBD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarization"
      ],
      "metadata": {
        "id": "TYGz33vIUQyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Language Translation"
      ],
      "metadata": {
        "id": "Exjqg3EjUh1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "language_sequence = (\"You should definitely watch 'One Piece', it is so good, you will love the comic book\")"
      ],
      "metadata": {
        "id": "aE0TGXgIUS8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(\"translate English to French: \"+language_sequence, return_tensors=\"pt\").input_ids"
      ],
      "metadata": {
        "id": "FlWMhgN6Uzzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language_ids = model.generate(input_ids)"
      ],
      "metadata": {
        "id": "JCr3XnThU5Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language_translation = tokenizer.decode(language_ids[0],skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "IR5govHBVc1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language_translation"
      ],
      "metadata": {
        "id": "0pB0jQQfVjcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Text Classification: Textual Entailment"
      ],
      "metadata": {
        "id": "Qfqln3-MXngd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entailment_premise = (\"I love One Piece.\")\n",
        "entailment_hypothesis = (\"My feelings towards One Piece is filled with love\")"
      ],
      "metadata": {
        "id": "2Tq4ZlrYVlHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(\"mnli premise: \"+entailment_premise+\" hypothesis: \"+entailment_hypothesis, return_tensors=\"pt\").input_ids"
      ],
      "metadata": {
        "id": "ifbllaToXqNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entailment_ids = model.generate(input_ids)"
      ],
      "metadata": {
        "id": "_1KygdhfX2Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entailment = tokenizer.decode(entailment_ids[0],skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "bGxZ03lHX6R9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entailment"
      ],
      "metadata": {
        "id": "fNWsOq6xX_PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Linguistic Acceptability"
      ],
      "metadata": {
        "id": "rsYlFRORYCz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = (\"Luffy is a great pirate.\")"
      ],
      "metadata": {
        "id": "gm5IeJ4NYARH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(\"cola: \"+ sentence, return_tensors=\"pt\").input_ids"
      ],
      "metadata": {
        "id": "QQ5z5qXnYNVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_ids = model.generate(input_ids)"
      ],
      "metadata": {
        "id": "zrh1lvTtYU3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = tokenizer.decode(sentence_ids[0],skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "F_z6lDwQYX_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence"
      ],
      "metadata": {
        "id": "AbvonXqJYcdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Sentence Similarity"
      ],
      "metadata": {
        "id": "TsgfoMlhYpIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stsb_sentence_1 = (\"Luffy was fighting in the war.\")\n",
        "stsb_sentence_2 = (\"Luffy's fighting style is comical.\")"
      ],
      "metadata": {
        "id": "CUxJb9u8Yc9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(\"stsb sentence 1: \"+stsb_sentence_1+\" sentence 2: \"+stsb_sentence_2, return_tensors=\"pt\").input_ids"
      ],
      "metadata": {
        "id": "j7azydeQY1pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stsb_ids = model.generate(input_ids)"
      ],
      "metadata": {
        "id": "ubAVSTAkZCnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stsb = tokenizer.decode(stsb_ids[0],skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "RgDM_CU6ZFno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stsb"
      ],
      "metadata": {
        "id": "Mfl5RAMNZJc1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}